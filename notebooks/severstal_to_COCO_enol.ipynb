{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.317343Z",
     "start_time": "2025-01-16T18:34:44.312510Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from itertools import groupby\n",
    "from skimage import io\n",
    "from sympy.core.random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pycocotools.mask as mask_util"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.364901Z",
     "start_time": "2025-01-16T18:34:44.360714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    \"\"\"\n",
    "    Decodes run-length encoded segmentation mask string into 2d array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param rle_mask (str): Run-length encoded segmentation mask string.\n",
    "    :param shape (tuple): (height, width) of array to return\n",
    "    :return mask [numpy.ndarray of shape (height, width)]: Decoded 2d segmentation mask\n",
    "    \"\"\"\n",
    "    # Splits the RLE string into a list of string by whitespaces.\n",
    "    s = mask_rle.split()\n",
    "\n",
    "    # This creates two numpy arrays, one with the RLE starts and one with their respective lengths\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "\n",
    "    # To obtain the end point we need to substract 1 to the length or start because the initial point counts.\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "\n",
    "    # Create a 1D array of size H*W of zeros\n",
    "    mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "\n",
    "    # Fill this array with ones in the positions where there is a mask using the RLE information\n",
    "    for start, end in zip(starts, ends):\n",
    "        mask[start:end] = 1\n",
    "\n",
    "    # Reshape the 1D array into a 2D array so we can finally get the binary 2D mask.\n",
    "    mask = mask.reshape(shape)\n",
    "    return mask.T"
   ],
   "id": "bed650c9184cb5b7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.413015Z",
     "start_time": "2025-01-16T18:34:44.409093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_mask_to_rle(binary_mask):\n",
    "    \"\"\"\n",
    "    Checkout: https://cocodataset.org/#format-results\n",
    "    :param mask [numpy.ndarray of shape (height, width)]: Decoded 2d segmentation mask\n",
    "\n",
    "    This function returns the following dictionary:\n",
    "    {\n",
    "        \"counts\": encoded mask suggested by the official COCO dataset webpage.\n",
    "        \"size\": the size of the input mask/image\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Create dictionary for the segmentation key in the COCO dataset\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    # We need to convert it to a Fortran array\n",
    "    binary_mask_fortran = np.asfortranarray(binary_mask)\n",
    "    # Encode the mask as specified by the official COCO format\n",
    "    encoded_mask = mask_util.encode(binary_mask_fortran)\n",
    "    # We must decode the byte encoded string or otherwise we cannot save it as a JSON file\n",
    "    rle[\"counts\"] = encoded_mask[\"counts\"].decode()\n",
    "    return rle"
   ],
   "id": "6fc665afd8700968",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.467049Z",
     "start_time": "2025-01-16T18:34:44.456889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_coco_format_json(data_frame, classes, filepaths, split=0.7):\n",
    "    \"\"\"\n",
    "    This function creates a COCO dataset.\n",
    "    :param data_frame: pandas dataframe with an \"id\" column.\n",
    "    :param classes: list of strings where each string is a class.\n",
    "    :param filepaths: a list of strings containing all images paths\n",
    "    :return dataset_coco_format: COCO dataset (JSON).\n",
    "    \"\"\"\n",
    "    images_train = []\n",
    "    images_val = []\n",
    "    annotations_train = []\n",
    "    annotations_val = []\n",
    "    categories = []\n",
    "    count_train = 0\n",
    "    count_val = 0\n",
    "\n",
    "    # Creates a categories list, i.e: [{'id': 0, 'name': 'a'}, {'id': 1, 'name': 'b'}, {'id': 2, 'name': 'c'}]\n",
    "    for idx, class_ in enumerate(classes):\n",
    "        categories.append(\n",
    "            {\n",
    "                \"id\": class_,\n",
    "                \"name\": f'class_{class_}'\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Iterate over image filepaths\n",
    "    for file in tqdm(filepaths):\n",
    "        train_sample = True if random.random() < split else False\n",
    "        file = file[-15:]  #Get only the name\n",
    "        cond = data_frame['ImageId'] == file\n",
    "        index_list = data_frame.index[cond].tolist()\n",
    "        # Get the image id, e.g: \"10044\"\n",
    "        #print(filepath)\n",
    "        file_id = file\n",
    "        #print(file_id)\n",
    "        # Get the image height, e.g: 360 (px)\n",
    "        height = 256\n",
    "        # Get the image width, e.g: 310 (px)\n",
    "        width = 256\n",
    "        # One image has many annotations associated to it (1 for each class), get a list with the indices.\n",
    "        #print(ids)\n",
    "        # Get filename\n",
    "        file_name = file_id\n",
    "        # Adding images which have annotations\n",
    "        img = {\n",
    "                \"id\": file_id,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"file_name\": file_name}\n",
    "        if train_sample: \n",
    "            images_train.append(img) \n",
    "        else:\n",
    "            images_val.append(img)\n",
    "        \n",
    "        if len(index_list) == 0: # there is no defect on the image\n",
    "            mk = np.zeros((256,256), dtype=np.uint8) # create blank mask\n",
    "            enc = binary_mask_to_rle(mk)\n",
    "            seg = {\n",
    "                'segmentation': enc,\n",
    "                'bbox': [None, None, None, None],\n",
    "                'area': None,\n",
    "                'image_id':file_id,\n",
    "                'category_id': 5,\n",
    "                'iscrowd':0,\n",
    "                'id': count_train if train_sample else count_val\n",
    "            }\n",
    "            if train_sample:\n",
    "                annotations_train.append(seg)\n",
    "                count_train +=1\n",
    "            else:\n",
    "                annotations_val.append(seg)\n",
    "                count_val +=1\n",
    "        else:\n",
    "            for idx in index_list:\n",
    "                mk = rle_decode(data_frame.iloc[idx]['EncodedPixels'], (256, 256))\n",
    "                ys, xs = np.where(mk)\n",
    "                x1, x2 = min(xs), max(xs)\n",
    "                y1, y2 = min(ys), max(ys)\n",
    "                enc = binary_mask_to_rle(mk)\n",
    "                seg = {\n",
    "                    'segmentation': enc,\n",
    "                    'bbox': [int(x1), int(y1), int(x2-x1+1), int(y2-y1+1)],\n",
    "                    'area': int(np.sum(mk)),\n",
    "                    'image_id':file_id,\n",
    "                    'category_id':int(data_frame.iloc[idx]['ClassId']),\n",
    "                    'iscrowd':0,\n",
    "                    'id': count_train if train_sample else count_val\n",
    "                }\n",
    "                if train_sample:\n",
    "                    annotations_train.append(seg)\n",
    "                    count_train +=1\n",
    "                else:\n",
    "                    annotations_val.append(seg)\n",
    "                    count_val +=1\n",
    "\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset_train_coco_format = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": images_train,\n",
    "        \"annotations\": annotations_train,\n",
    "    }\n",
    "    dataset_val_coco_format = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": images_val,\n",
    "        \"annotations\": annotations_val,\n",
    "    }\n",
    "\n",
    "    return dataset_train_coco_format, dataset_val_coco_format\n",
    "\n",
    "\n",
    "def sep():\n",
    "    print(\"-\"*100)"
   ],
   "id": "485c17c6ae08facb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.512524Z",
     "start_time": "2025-01-16T18:34:44.509472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "height = 256\n",
    "width = 256\n",
    "data_path = '/home/eas/Enol/pycharm_projects/clipseg_steel_defect/Severstal/train_subimages'"
   ],
   "id": "93ea49a9ba0703c0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:44.985345Z",
     "start_time": "2025-01-16T18:34:44.557026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('/home/eas/Enol/pycharm_projects/clipseg_steel_defect/Severstal/subimages.csv')\n",
    "#Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ],
   "id": "ab1222482c34e04b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:45.012728Z",
     "start_time": "2025-01-16T18:34:45.009655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = sorted(df[\"ClassId\"].unique().tolist())\n",
    "classes.append(5)  # Class for images without any defect"
   ],
   "id": "6f22928d1d6d2e55",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:34:45.190797Z",
     "start_time": "2025-01-16T18:34:45.057659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filepaths = list()\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(data_path):\n",
    "    filepaths += [os.path.join(dirpath, file) for file in filenames if file.endswith(\".png\")]"
   ],
   "id": "b953828971eef352",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:37:09.949521Z",
     "start_time": "2025-01-16T18:34:45.226199Z"
    }
   },
   "cell_type": "code",
   "source": "g_json_train, g_json_val = create_coco_format_json(df, classes, filepaths, 0.8)",
   "id": "3d04691a2578bb96",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87976/87976 [02:24<00:00, 607.91it/s]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:37:11.858683Z",
     "start_time": "2025-01-16T18:37:09.962828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('/home/eas/Enol/pycharm_projects/clipseg_steel_defect/Severstal/annotations_COCO_train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(g_json_train, f, indent=4)"
   ],
   "id": "ba8fef62360c26b6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:37:12.294431Z",
     "start_time": "2025-01-16T18:37:11.873200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('/home/eas/Enol/pycharm_projects/clipseg_steel_defect/Severstal/annotations_COCO_val.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(g_json_val, f, indent=4)"
   ],
   "id": "22bc3c5ef17fc116",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T18:37:12.307300Z",
     "start_time": "2025-01-16T18:37:12.305490Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ea2a5c446cbdcf02",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
